{
 "metadata": {
  "name": "",
  "signature": "sha256:0621528d5f5e0c334deabcbbafbf87ec2678c386fa1698e5d145d08d559c8d7d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"header\"></a>\n",
      "**License**: BSD<br>\n",
      "**Copyright**: Copyright American Gut Project, 2014<br>\n",
      "\n",
      "<a id=\"intro\"></a>\n",
      "# Preprocessing and File Generation\n",
      "\n",
      "The goal of this notebook is to take the OTU table and mapping files generated by the American Gut  Primary Processing Pipeline Notebook and massage them into a uniform set of rarefied and filtered tables which can be used in downstream analyses, such as our Power Notebook, or using  <a href=\"http://qiime.org\">Qiime</a>, <a href=\"http://biocore.github.io/emperor/\">EMPeror</a>, or <a href=\"http://picrust.github.io/picrust/\">PICRUSt</a> [<a href=\"#20383131\">1 - 3</a>]. This processing is centralized since it can be computationally expensive, given the size of the tables involved, and because it removes some error associated with the random number generation used in some steps.\n",
      "\n",
      "<a id=\"intro_data\"></a>\n",
      "### Data Sets Generated by this Notebook\n",
      "This notebook will generate sample sets for all the human body sites the American Gut Table (fecal, oral and skin). You can download these files as a group in a <a href=\"https://www.dropbox.com/s/224fcj6hvv9ol07/sample_data.tgz\"> single directory</a>. Alternatively, you can download the individual directories by clicking on the links below.\n",
      "<ul><li><a href=\"https://www.dropbox.com/s/x70bauf6k5cs59e/all.tgz\">All Body Sites</a>\n",
      "</li><li><a href=\"https://www.dropbox.com/s/hj4xb0s2pxld86o/fecal.tgz\">Fecal Samples</a>\n",
      "<ul><li>Fecal: <a href=\"https://www.dropbox.com/s/la3q3zntacei1c2/all_participants_all_samples.tgz\">all subjects, all observations</a>\n",
      "</li><li>Fecal: <a href=\"https://www.dropbox.com/s/bf4iiic9t1sdwcv/all_participants_one_sample.tgz\">all subjects, single observation per subject</a>\n",
      "</li><li>Fecal: <a href=\"https://www.dropbox.com/s/w40kysuwa5m24ua/sub_participants_all_samples.tgz\">healthy subjects, all observations</a>\n",
      "</li><li>Fecal: <a href=\"https://www.dropbox.com/s/5gx2whigjhlcdhv/sub_participants_one_sample.tgz\">healthy subjects, single observation per subject</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"https://www.dropbox.com/s/3xjepiqn76qzq2l/oral.tgz\">Oral Samples</a>\n",
      "<ul><li>Oral: <a href=\"https://www.dropbox.com/s/xbbub1aavspk3dj/all_participants_all_samples.tgz\">all subjects, all observations</a>\n",
      "</li><li>Oral: <a href=\"https://www.dropbox.com/s/xsnrb8urkaa5vxv/all_participants_one_sample.tgz\">all subjects, single observation per subject</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"https://www.dropbox.com/s/3xjepiqn76qzq2l/oral.tgz\">Skin Samples</a>\n",
      "<ul><li>Skin: <a href=\"https://www.dropbox.com/s/qjge78q39m7kqj6/all_participants_all_samples.tgz\">all subjects, all observations</a>\n",
      "</li><li>Skin: <a href=\"https://www.dropbox.com/s/ittttkr28ebru7n/all_participants_one_sample.tgz\">all subjects, single observation per subject</a>\n",
      "</li></ul>\n",
      "</li></ul>\n",
      "\n",
      "<a id=\"intro_files\"></a>\n",
      "### Files and File Types\n",
      "Our folders will contain three types of files: two metadata files, two biom-format OTU table files and two distance matrices:\n",
      "* AGP_100nt_fecal.txt<sup>*</sup> (metadata)\n",
      "* AGP_100nt_fecal.biom<sup>*</sup> (otu table)\n",
      "* AGP_100nt_fecal_even10k.txt<sup>*</sup> (metadata)\n",
      "* AGP_100nt_fecal_even10k.biom<sup>*</sup> (otu table)\n",
      "* unweighted_unifrac_AGP_100nt_fecal_even10k.txt<sup>*</sup> (distance matrix)\n",
      "* weighted_unifrac_AGP_100nt_fecal_even10k.txt<sup>*</sup> (distance matrix)\n",
      "\n",
      "<sup>*</sup>fecal may be substituted for the appropriate bodysite.\n",
      "\n",
      "Let\u2019s talk a bit more about what information is contained in each file type.\n",
      "\n",
      "<a id=\"ftype_map\"></a>\n",
      "#### Metadata\n",
      "A **metadata file**, sometimes called a **mapping file**, provides information about our samples which we cannot determine by 16S analysis. This is as important as the bacterial sequence information for determining information about the microbiome. Metadata tells us information about the sample, such as the body site where it was collected, the participant\u2019s age or whether or not they have certain diseases. Since these can make a very large difference in the microbiome, it\u2019s important to have this information!\n",
      "\n",
      "American Gut metadata is collected through the participant survey. The survey allows participants to skip any question they do not wish to answer, meaning that some samples are missing fields. The way we handle data in these notebooks will be able to properly encode and handle this missing data. The American Gut metadata is also de-identified. This means the metadata does not contain information which could be used to identify a participant, like their name, email address, or the kit ID. Instead, each participant is assigned a code. This allows us to identify multiple samples from the same individual. The samples are identified by the barcode number, which appears on the sample tube. This number connects the survey metadata to the sample data in hte OTU table and distance matrix.\n",
      "\n",
      "You can learn more about Qiime-compliant mapping files [here](http://qiime.org/documentation/file_formats.html#metadata-mapping-files).\n",
      "\n",
      "<a id=\"ftype=otu\"></a>\n",
      "#### OTU Table\n",
      "An **OTU table** describes the bacterial content in a group of sample. An OTU, or operational taxonomic unit, is a cluster of sequences which are identical to some degree of similarity. We use these as stand-ins for bacterial groups. More information about OTUs, the level of similarity used, and the methods we use to generate OTUs can be found in the [Primary Processing Pipeline Notebook](http://nbviewer.ipython.org/github/biocore/American-Gut/blob/master/ipynb/module2_v1.0.ipynb). The OTU table allows us to link the sequencing results from our 16s data to the sample ID in a usable way, and gives an easier platform for comparing across samples. Our OTU tables are saved as a special file format, called a [biom file](http://www.biom-format.org) [<a href=\"#23587224\">4</a>]. Unlike the other file types we will generate here, biom files cannot be viewed using a normal spreadsheet program on your computer. The benefit of biom format is that is allows us to save large amounts of data in a smaller amount of space. The biom-format we will use here encodes information the same way NASA does!\n",
      "\n",
      "<a id=\"ftype_dist\"></a>\n",
      "#### Distance Matrix\n",
      "\n",
      "Finally, Distance Matrices describe the relationship between any two samples based on their community structure. In this notebook, we will measure the UniFrac Distance between all of our samples. This takes into account the evolutionary relationship between bacteria when communities are compared [<a href=\"16332807\">5</a>, <a href=\"20827291\">6</a>]. Each cell in the distance matrix tells the distance between the sample given by the row and the sample given by the column. Distance matrices are typically symmetrical, which means that we can draw a line down a diagonal of the distance matrix, and the distances on either side of this line will be equal. The distances along that line should come from the same sample, and will have a distance of 0. We can use our distance matrix information directly, or use multidimensional scaling techniques like <a href=\"http://occamstypewriter.org/boboh/2012/01/17/pca_and_pcoa_explained/\">Principal Coordinates Analysis (PCoA)</a> or make a <a href=\"http://en.wikipedia.org/wiki/UPGMA\">UPGMA tree</a>.\n",
      "\n",
      "<table id=\"ftype\">\n",
      "<tr><td>\n",
      "</td><th background-color=\"#eee\">Metadata\n",
      "</th><th>OTU Table\n",
      "</th><th>Distance Matrix\n",
      "</th></tr>\n",
      "<tr><th>Example File\n",
      "</th><td>AGP_100nt_even10k.txt\n",
      "</td><td>AGP_100nt_even10k.biom\n",
      "</td><td>unweighted_unifrac_AGP_100nt_even10k.txt\n",
      "</td></tr>\n",
      "<tr><th>File Type\n",
      "</th><td>tab-delimted text file<br>(ends in .txt)\n",
      "</td><td><a href=\"http://www.biom-format.org\">biom-format file</a>[<a href=\"#23587224\">4</a>]<br>(ends in .biom)\n",
      "</td><td>tab-delimted text file<br>(ends in .txt)\n",
      "</td></tr>\n",
      "<tr><th>Other viewing option\n",
      "</th><td>text editor (i.e. Emacs, sublime text, TextEdit)\n",
      "Spreadsheet program (i.e. Excel)\n",
      "</td><td>Using the biom-format python package\n",
      "</td><td>text editor (i.e. Emacs, sublime text, TextEdit)\n",
      "Spreadsheet program (i.e. Excel)\n",
      "</td></tr>\n",
      "<tr><th>Rows\n",
      "</th><td>Samples are in rows. \n",
      "</td><td>OTU sequence clusters are the rows in the table.\n",
      "</td><td>Rows are samples.\n",
      "</td></tr>\n",
      "<tr><th>Columns\n",
      "</th><td>Columns are metadata categories like AGE, BMI or disease status.\n",
      "</td><td>Columns are samples\n",
      "</td><td>Columns are samples.\n",
      "</td></tr>\n",
      "</table>\n",
      "\n",
      "<a href=\"#top\">Return to the Table of Contents</a>\n",
      "\n",
      "<a id=\"#reqs\"></a>\n",
      "## Notebook Requirements\n",
      "* [Python 2.7.3](https://www.python.org/download/releases/2.7/)\n",
      "* [Qiime 1.9](https://www.qiime.org/install/install.html)\n",
      "* [h5py](http://www.h5py.org). This is required to run the biom software for Qiime. It is not installed automatically when you use pip for biom format or Qiime.\n",
      "* [Jinja2](http://jinja.pocoo.org/docs/dev/), [pyzmq](https://learning-0mq-with-pyzmq.readthedocs.org/en/latest/) and  [tornado](http://www.tornadoweb.org/en/stable/). These are required to open a local IPython notebook instance. They are not installed automatically when you use pip to install IPython or install IPython as a dependency for Qiime.\n",
      "* [Statsmodels 0.6.0](http://statsmodels.sourceforge.net)\n",
      "* [American Gut Python Library](https://github.com/biocore/American-Gut)\n",
      "\n",
      "$\\LaTeX$ is also recommended for running this suite of analysis notebooks, although it is not required for this notebook. [LiveTex](http://www.tug.org/texlive/) offers one installation solution.\n",
      "\n",
      "<a id=\"top\"></a>\n",
      "## Table of Contents\n",
      "<ul><li><a href=\"#intro\">Introduction</a>\n",
      "<ul><li><a href=\"#intro_data\">Data Sets Generated by This Notebook</a>\n",
      "</li><li><a href=\"#intro_files\">Files and File Types</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#reqs\">Notebook Requirements</a>\n",
      "</li><li><a href=\"#imports\">Function Imports</a>\n",
      "</li><li><a href=\"#params\">Analysis Parameters</a>\n",
      "<ul><li><a href=\"#params_meta\">Metadata and text file handing Parameters</a>\n",
      "</li><li><a href=\"#params_filt\">Filtering Parameters</a>\n",
      "</li><li><a href=\"#params_rare\">Rarefaction Parameters</a>\n",
      "</li><li><a href=\"#params_split\">Split Parameters</a>\n",
      "</li><li><a href=\"#params_alpha\">Alpha Diversity Parameters</a>\n",
      "</li><li><a href=\"#params_beta\">Beta Diversity Parameters</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#datasets\">Data Set Selection</a>\n",
      "</li><li><a href=\"#dir\">Filepaths and Directories</a>\n",
      "<ul><li><a href=\"#dir_base\">Base Directory</a>\n",
      "</li><li><a href=\"#dir_ref\">Reference Directories and Files</a>\n",
      "</li><li><a href=\"#dir_work\">Working Directories and Files</a>\n",
      "</li><li><a href=\"#dir_save\">Output Directories and Files</a>\n",
      "</li><li><a href=\"#dir_blanks\">File Pattern Fill-ins</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#download\">Data Download</a>\n",
      "</li><li><a href=\"#map_clean\">Mapping File Clean up</a>\n",
      "<ul><li><a href=\"#map_age\">Age</a>\n",
      "</li><li><a href=\"#map_etoh\">Alcohol Consumption</a>\n",
      "</li><li><a href=\"#map_bmi\">Body Mass Index</a>\n",
      "</li><li><a href=\"#map_date\">Collection Season</a>\n",
      "</li><li><a href=\"#map_loc\">Collection Location</a>\n",
      "</li><li><a href=\"#map_sleep\">Sleep Duration</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#subset\">Identification of a Healthy Subset of Adults</a>\n",
      "</li><li><a href=\"#rare\">Whole Table Rarefaction</a>\n",
      "</li><li><a href=\"#alpha\">Whole Table Alpha Diversity</a>\n",
      "</li><li><a href=\"#beta\">Whole Table Beta Diversity</a>\n",
      "</li><li><a href=\"#split\">Split the Whole Table by Body Site</a>\n",
      "</li><li><a href=\"#single\">Select a Single Sample for each Participant</a>\n",
      "</li><li><a href=\"#filt_subset\">Filter the Healthy Subset of Adults</a>\n",
      "</li><li><a href=\"#references\">References</a>\n",
      "</li></ul>\n",
      "\n",
      "<a id=\"imports\"></a>\n",
      "## Function Imports\n",
      "We will start our analysis by importing the functions we need from python libraries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import shutil\n",
      "import copy\n",
      "import datetime\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import skbio\n",
      "import biom\n",
      "\n",
      "from americangut.diversity_analysis import check_dir, pad_index\n",
      "from americangut.geography_lib import (regions_by_state,\n",
      "                                       us_state_map,\n",
      "                                       canadian_map_english)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params\"></a>\n",
      "## Analysis Parameters\n",
      "It is also important to define certain aspects of how we'll handle files and do our analysis. It can be easier to set all these at the same time, so the systems are consistent every time we repeat the process, rather than repeat them multiple places. This way, we only have to change the parameter once.\n",
      "\n",
      "<a id=\"params_meta\"></a>\n",
      "### Metadata and text file handling parameters\n",
      "We'll start by defining how we'll handle certain files, especially metadata files. We will use the Pandas library to handle most of our text files. This library gives some spreadsheet like functionalities.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>overwrite</strong><br>(boolian)\n",
      "</td><td>When <strong><code>overwrite</code></strong> is <code><font color=\"228B22\">True</font></code>, new files will be generated and saved during data processing. <br>It is recommended that overwrite be set to <code><font color=\"228B22\">False</font></code>, in which case new files will only be generated when the file does not exist. This substantially decreases analysis time.\n",
      "</td></tr>\n",
      "<tr><td>**txt_delim**<br>(string)\n",
      "</td><td><strong><code>txt_delim</code></strong> specifies the way columns are separated in the files. Qiime typically consumes and produces tab-delimited (<code><font color=\"FireBrick\">\"\\t\"</font></code>) text files (.txt) for metadata and results generation.\n",
      "</td></tr>\n",
      "<tr><td>**map_index**<br>(string)\n",
      "</td><td>The name of the column containg the sample names. In Qiime, this column is called <code><font color=\"FireBrick\">#SampleID</font></code>.\n",
      "</td><tr>\n",
      "<tr><td>**map_nas**<br>(list of strings)\n",
      "</td><td>t is possible a mapping file map be missing values, since American Gut participants are free to skip any question. The pandas package is able to omit these missing samples from analysis. In raw American Gut files, missing values are typically denoted as <code><font color=\"FireBrick\">\u201cNA\u201d</font></code>, <code><font color=\"FireBrick\">\u201cno_data\u201d</font></code>, <code><font color=\"FireBrick\">\u201cunknown\u201d</font></code>, and empty spaces (<code><font color=\"FireBrick\">\u201c\u201d</font></code>).\n",
      "</td><tr>\n",
      "<tr><td>**write_na** (string)\n",
      "</td><td>The value to denote missing values when text files are written from Pandas data frames. Using an empty space, (<code><font color=\"FireBrick\">\u201c\u201d</font></code>) will allow certain Qiime scripts, like [group_signigance.py](http://qiime.org/scripts/group_significance.html), will ignore the missing values.\n",
      "</td><tr>\n",
      "<tr><td>**date_cols** (list of strings)\n",
      "</td><td>Temporal data can be identified using the <strong><code>date_cols</code></strong>, allowing the Pandas program to do time-based analysis. In the American Gut dataset, there are four we identify initially: *BIRTH_DATE* (the participant\u2019s birthdate), *COLLECTION_DATE* (the day the sample was collected), *SAMPLE_TIME* (the time the sample was collected), and *RUN_DATE* (the day the samples were sequenced).\n",
      "</td><tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "overwrite = False\n",
      "txt_delim = '\\t'\n",
      "map_index = '#SampleID'\n",
      "map_nas = ['NA', 'no_data', 'unknown', '']\n",
      "write_na = ''\n",
      "date_cols = ['RUN_DATE', 'COLLECTION_DATE', 'BIRTH_DATE', 'SAMPLE_TIME']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params_rare\"></a>\n",
      "### Rarefaction parameters\n",
      "\n",
      "We rarefy our data to set an even depth and allow head-to-head comparison of alpha and beta diversity. Rarefaction begins by removing samples from the table which do not have the minimum number of counts. Sequences are then drawn randomly out of a weighted pool until we reach the appropriate number.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr>\n",
      "<td>**rarefaction_depth**<br>(int)\n",
      "</td><td>The <strong><code>rarefaction_depth</code></strong> specifies the number of sequence per samples to be used for analysis. A depth of 10,000 seqs/sample was selected  because it balances a better picture of diversity with retaining samples. \n",
      "</td>\n",
      "</tr><tr>\n",
      "<td>**num_rarefactions**<br>(int)\n",
      "</td><td>The number of times we draw new rarefaction tables. This controls for bias due to single rarefaction instances. We selected 10 rarefactions to achieve a balance between computational efficiency and appropriate depth.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rarefaction_depth = 10000\n",
      "num_rarefactions = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params_split\"></a>\n",
      "### Split Parameters\n",
      "\n",
      "We will split our OTU tables by body site, since the collection site on the human body plays a large role in community compositions in healthy adults [<a href=\"#22699609\">7</a>].\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>split_field</strong><br>(string)\n",
      "</td><td>The metadata category which contains the body site information we will use to split the OTU table and mapping file.\n",
      "</td></tr>\n",
      "<tr><td><strong>split_prefix</strong><br>(string)\n",
      "</td><td>Under the standards used to format the American Gut metadata, a constant prefix is used to denote bodysite. This is used for string formatting and file naming.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_field = 'BODY_HABITAT'\n",
      "split_prefix = 'UBERON:'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params_alpha\"></a>\n",
      "### Alpha Diversity Parameters\n",
      "\n",
      "Alpha diversity looks at the variety of species within a sample. In this notebook, we calculate alpha diversity using a variety of metrics, and append these to the mapping file.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>alpha_metrics</strong><br>(string)\n",
      "</td><td>There are multiple alpha diversity metrics which can be used. We will calculate four alpha diversity metrics here: PD Whole Tree [<a href=\"#15831718\">8</a>], Observed Species, Chao1 [<a href=\"#Chao\">9</a>], and Shannon [<a href=\"#shannon\">10</a>] diversity. Among these metrics, PD whole tree diversity is unique in that it considers the evolutionary relationship between OTUs in a sample by calculating the branch length on the phylogenetic tree covered by a sample. A list of available metrics can be found on the [scikit-bio website](http://scikit-bio.org/docs/latest/generated/skbio.diversity.alpha.html) and in the documentation for the Qiime script, [alpha_diversity.py](http://qiime.org/scripts/alpha_diversity.html). (Pass the <code>-s</code> flag). Metric names should be connected with a comma (and no spaces).\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_metrics = 'PD_whole_tree,observed_species,chao1,shannon'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"params_beta\"></a>\n",
      "### Beta Diversity Parameters\n",
      "\n",
      "Beta Diversity compares the ecology community across multiple sites.  We will use Qiime to calculate beta diversity.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td>**beta_metrics**<br>(string)\n",
      "</td><td>As with alpha diversity, there are multiple ways we can can calculate our beta diversity metrics. Here, we use weighted and unweighted UniFrac distance [<a href=\"#16332807\">5</a>]. UniFrac distance determines the amount of the phylogenetic tree which does not overlap between two samples. Weighted UniFrac takes into account the abundance of a taxa within a sample, while unweighted UniFrac distance only considers the presence or absence of a particular bacteria. Additional options are available in the documentation for [beta_diversity.py](http://qiime.org/scripts/beta_diversity.html).\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta_metrics = \"unweighted_unifrac,weighted_unifrac\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"datasets\"></a>\n",
      "## Data Set Selection\n",
      "We can select the datasets which we\u2019ll generate using this notebook. The default for each body site is to generate a <a href=\"#intro_files\">data set</a> (OTU table, mapping file and distance matrices) for all participants and all samples.  We may want to limit our samples to a <a href=\"#single\">single sample per individual</a>. Or, we could choose only to work with a subset of the data (see <a href=\"#subset\">Identification of a Healthy Subset of Adults</a>).\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>habitat_bodysite</strong><br>(list of strings)\n",
      "</td><td>A list of the body site names used by our American Gut metadata standards. Some of these are not less convenient for file naming, and so we will rename some of these fields using the corresponding <strong><code>all_bodysites</code></strong> name. For example, the standard name for a mouth sample is to label it as an <code><font color=\"FireBrick\">\u201coral cavity\u201d</font></code>  sample, but spaces in file paths make life difficult, so this is mapped to <code><font color=\"FireBrick\">\u201coral\u201d</font></code> in our <strong><code>all_bodysites</code></strong> list.\n",
      "</td></tr>\n",
      "<tr><td><strong>all_bodysites</strong><br>(list of strings)\n",
      "</td><td>A list of all the possible body sites which will be used to generate the datasets here. The order of bodysites must correspond to the order of bodysites in <strong><code>habitat_bodysites</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>sub_part_sites</strong><br>(set)\n",
      "</td><td>We may also want to generate data set which limits our sample set to exclude samples which are already known to affect the microbiome. The subset currently being selected focuses mainly on fecal samples.\n",
      "</td></tr>\n",
      "<tr><td><strong>one_samp_sites</strong><br>(set)\n",
      "</td><td>For some types of analysis, there is an assumption that samples are independent</a>, which in this context includes the requirement that there are not multiple samples per individual. To limit analysis to a single sample from each individual, we can select body site where we want to filter for a single sample per individual. We recommend doing this for all body sites.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lists all bodysites to be analyzed\n",
      "habitat_sites = ['feces', 'oral cavity', 'skin']\n",
      "all_bodysites = ['fecal', 'oral', 'skin']\n",
      "\n",
      "# Handles healthy subset OTU tables\n",
      "sub_part_sites = {'fecal'}\n",
      "\n",
      "# Handles single sample OTU tables\n",
      "one_samp_sites = {'fecal', 'oral', 'skin'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir\"></a>\n",
      "##File paths and Directories\n",
      "To help organize the results of this notebook, we\u2019ll start by setting up a series of files where results can be saved. This will provide a common file structure (base_directory, sample_directory, etc) for the results. We\u2019re going to set up three primary directories here, and then nest additional directories inside.\n",
      "\n",
      "As we set up directories, we\u2019ll make use the of the **check_dir** function. This will create the directories we identify if they do not exist.\n",
      "\n",
      "<a id=\"dir_base\"></a>\n",
      "### Base Directory\n",
      "We need a general location to do all our analysis; this is the base_dir. All our other directories will exist within the base_dir, and allow us to work.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td>**base_dir**<br>(string)\n",
      "</td><td>The filepath for the directory where any files associated with the analysis should be saved. It is suggested this be a directory called <code><font color=\"FireBrick\">\"agp_analysis\"</font></code>, located in the same directory as the IPython notebooks.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# base_dir = os.path.join(os.path.abspath('.'), 'agp_analysis')\n",
      "base_dir = os.path.join('/Users/jwdebelius/Desktop/agp_analysis2')\n",
      "check_dir(base_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"dir_ref\"></a>\n",
      "### Reference Directories and Files\n",
      "\n",
      "Some of the steps in our diversity calculations will require a phylogenetic tree. This contains information about the evolutionary relationship between OTUs which can be leveraged in calculating PD Whole Tree Diversity and UniFrac Distance.\n",
      "While there are multiple ways to pick OTUs, this table was generated using a reference-based technique. Therefore, we can simply download the phylogenetic tree file for the reference set. Our reference for this dataset was the greengenes version 13_5 at 97% similarity [<a href=\"#22134646\">11</a>]. Please refer to the [Primary Processing Pipeline Notebook](http://nbviewer.ipython.org/github/biocore/American-Gut/blob/master/ipynb/module2_v1.0.ipynb) for more information about how OTUs are picked.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>gg_dir</strong><br>(string)\n",
      "</td><td>This specifies the location where your greengenes 13_8 reference set has been saved. \n",
      "The current file path assumes the greengenes file is saved in the lib folder in your home directory. It is recommended this be changed to reflect the actual location of your greengenes 13_8 files.\n",
      "</td></tr>\n",
      "<tr><td><strong>tree_fp</strong><br>(string)\n",
      "</td><td>The location of the correct tree file inside your greengenes 13_8 directory. It is not recommended this be changed without first consulting the Module 2 notebook to determine if the clustering level (currently 97% similarity) has been changed, as the level of similarity for a phylogenetic tree must correspond to the level of similarity used to pick the OTUs.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gg_dir = os.path.join(os.path.expanduser('~'), 'lib/Greengenes/gg_13_8_otus')\n",
      "tree_fp = os.path.join(gg_dir, 'trees/97_otus.tree')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir_work\"></a>\n",
      "### Working Directories and Files\n",
      "\n",
      "The working directories will be used to save files we generate as we clean up our data. These may include items like downloaded OTU tables, and rarefaction instances.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>working_dir</strong><br>(string)\n",
      "</td><td>The file path for a directory where intermediate files (i.e. rarefaction instances) generated during the run of this notebook can be stored. It is recommended this be located within the base analysis directory.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up a directory to save intermediate files and downloads\n",
      "working_dir = os.path.join(base_dir, 'intermediate_files')\n",
      "check_dir(working_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of our first analysis steps will to be to locate the filtered American Gut OTU tables. The tables may be generated locally, may be located in local GitHub Repository or they may be downloaded directly from GitHub. \n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>download_dir</strong><br>(string)\n",
      "</td><td>The file path were downloaded files should be saved. The <strong><code>download_dir</code></strong> may be located within the <strong><code>working_dir</code></strong>, it\u2019s also likely the <strong><code>download_dir</code></strong> may be located outside the <strong><code>base_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>download_otu_fp</strong><br>(string)\n",
      "</td><td>The uncompressed OTU table from Git is located at this filepath. This should be a .biom file, with no compression.\n",
      "</td></tr>\n",
      "<tr><td><strong>download_map_fp</strong><br>(string)\n",
      "</td><td>The location of the American Gut mapping file, downloaded from GitHub.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a directory for unprocessed file downloads\n",
      "download_dir = os.path.join(working_dir, 'downloads')\n",
      "check_dir(download_dir)\n",
      "\n",
      "# Sets the filepaths for downloaded files\n",
      "download_otu_fp = os.path.join(download_dir, 'AG_100nt.biom')\n",
      "download_map_fp = os.path.join(download_dir, 'AG_100nt.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At some point in our analysis, it will become necessary to spit our OTU table by bodysite. The directory we create next will specify the location, while the file patterns will allow us to iterate or select one of many possible files using a simple string substitution.\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>split__raw_dir</strong><br>(string)\n",
      "</td><td>The file path where we should put the un-rarefied OTU table after its been split by bodysite. This should be located in the <strong><code>working_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>split_rare_dir</strong><br>(string)\n",
      "</td><td>The file path where we should put the rarefied OTU table after its been split by bodysite. This should be located in the <strong><code>working_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>split_fn</strong><br>(string)\n",
      "</td><td>The files generated by OTU splitting will follow this naming convention. The blanks, <a href=\"#params_rare\">rare_suffix</a>, <a href=\"#params_split\">split_field</a>, <a href=\"#params_split\">split_prefix</a>, split_group and extension are used to specify the level of rarefaction, the field used for splitting the data, the group in that split, and the type of file generated. Here, we expect the split_group to be a body site.\n",
      "</td></tr>\n",
      "</table>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a directory for splitting the OTU table by bodysite\n",
      "split_raw_dir = os.path.join(working_dir, 'split_by_bodysite_raw')\n",
      "check_dir(split_raw_dir)\n",
      "split_rare_dir = os.path.join(working_dir, 'split_by_bodysite_rare')\n",
      "check_dir(split_rare_dir)\n",
      "\n",
      "# Sets a pattern for filenames in the split directory\n",
      "split_fn = 'AGP_100nt%(rare_suffix)s__%(split_field)s_%(split_prefix)s%(split_group)s__.%(extension)s'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we perform rarefaction on our data, we will generate several similarly named files. To help keep these organized, we will create a directory for each set of rarefaction files.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>rare_dir</strong><br>(string)\n",
      "</td><td>The file path to the directory where we should save all of our rarefaction files. This should be located in the <strong><code>working_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>rare_pattern</strong><br>(string)\n",
      "</td><td>This describes the way rarified OTU tables will be saved in our output directories. The <code><font color=\"FireBrick\">\u201c%i\u201d</font></code> will allow us to substitute any integers. In this case, we will specify the rarefaction depth, and the rarefaction instance for each table. \n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a parent directory for rarefaction instances\n",
      "rare_dir = os.path.join(working_dir, 'rarefaction')\n",
      "check_dir(rare_dir)\n",
      "\n",
      "# Sets a pattern for the filenames of the rarefaction files\n",
      "rare_pattern = 'rarefaction_%(rare_depth)i_%(rare_instance)i.biom'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we perform the alpha diversity on our data, we will use our similarly named rarefaction tables and generate several similarly named alpha diversity files. To help keep these organized, we will create a directory for each set of alpha diversity files.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>alpha_dir</strong><br>(string)\n",
      "</td><td>The file path to the directory where we should save all of our alpha diversity files. This should be located in the <strong><code>working_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>alpha_pattern</strong><br>(string)\n",
      "</td><td>This describes the way alpha diversity files will be saved in our output directories. The <code><font color=\"FireBrick\">\u201c%i\u201d</font></code> will allow us to substitute any integers. In this case, we will specify the rarefaction depth, and the rarefaction instance for each table.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a parent directory for the alpha diversity files\n",
      "alpha_dir = os.path.join(working_dir, 'alpha')\n",
      "check_dir(alpha_dir)\n",
      "\n",
      "# Sets a pattern for the filenames of alpha diversity tables\n",
      "alpha_pattern = 'alpha_rarefaction_%(rare_depth)i_%(rare_instance)i.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir_save\"></a>\n",
      "### Output Directories and Files\n",
      "\n",
      "Finally, we need to set up the directories and filenames where we will save our results. We\u2019ll start by creating an output directory where our results should be located. We will then create all directory and body site specific directories to save our output tables.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>data_dir</strong><br>(string)\n",
      "</td><td>The file path for a directory where the results of this notebook (OTU tables, mapping files, and distance matrices) should be saved. This should be a directory in <strong><code>base_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>all_dir</strong><br>(string)\n",
      "</td><td>The filepath for a directory where tables from this notebook describing the data at all sites in the American Gut should be stored. This should be a directory in <strong><code>data_dir</code></strong>.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up a directory where all results should be saved\n",
      "data_dir = os.path.join(base_dir, 'sample_data')\n",
      "check_dir(data_dir)\n",
      "\n",
      "# Sets up an all sample directory\n",
      "all_dir = os.path.join(data_dir, 'all')\n",
      "\n",
      "# Creates body-site specific directories\n",
      "for site in all_bodysites:\n",
      "    check_dir(os.path.join(data_dir, site))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will set up file names for the output directories where we\u2019ll save our final files. \n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>asab_pattern</strong><br>(string)\n",
      "</td><td>A file pattern for the directory where we\u2019ll save the data from all samples from all participants. The <code><font color=\"FireBrick\">\u201c%s\u201d</font></code> prefix will allow us to insert any file path for the output directory. We expect the final file paths used with these directories to be located in the <strong><code>data_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>assb_pattern</strong><br>(string)\n",
      "</td><td>A file pattern for the directory where we\u2019ll save the data from a single samples from each participant. The <code><font color=\"FireBrick\">\u201c%s\u201d</font></code> prefix will allow us to insert any file path for the output directory. We expect the final file paths used with these directories to be located in the <strong><code>data_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>ssab_pattern</strong><br>(string)\n",
      "</td><td>A file pattern for the directory where we\u2019ll save the data from all samples from a subset of participants. The <code><font color=\"FireBrick\">\u201c%s\u201d</font></code> prefix will allow us to insert any file path for the output directory. We expect the final file paths used with these directories to be located in the <strong><code>data_dir</code></strong>.\n",
      "</td></tr>\n",
      "<tr><td><strong>sssb_pattern</strong><br>(string)\n",
      "</td><td>A file pattern for the directory where we\u2019ll save the data from a single samples from each participant in the healthy subset. The <code><font color=\"FireBrick\">\u201c%s\u201d</font></code> prefix will allow us to insert any file path for the output directory. We expect the final file paths used with these directories to be located in the <strong><code>data_dir</code></strong>.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up the file path pattern for the possible sets of sample at each body\n",
      "# site\n",
      "asab_pattern = os.path.join(data_dir, '%(site)s/all_participants_all_samples')\n",
      "assb_pattern = os.path.join(data_dir, '%(site)s/all_participants_one_sample')\n",
      "ssab_pattern = os.path.join(data_dir, '%(site)s/sub_participants_all_samples')\n",
      "sssb_pattern = os.path.join(data_dir, '%(site)s/sub_participants_one_sample')\n",
      "\n",
      "# Checks the filepaths\n",
      "for site in all_bodysites:\n",
      "    site_blank = {'site': site}\n",
      "    check_dir(asab_pattern % site_blank)\n",
      "    if site in one_samp_sites:\n",
      "        check_dir(assb_pattern % site_blank)\n",
      "    if site in sub_part_sites:\n",
      "        check_dir(ssab_pattern % site_blank)\n",
      "    if site in sub_part_sites and site in one_samp_sites:\n",
      "        check_dir(sssb_pattern % site_blank)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we will set up file names for the file names we\u2019ll put in the output directories. We can combine these with our directories to get our final file paths.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>otu_fn</strong><br>(string)\n",
      "</td><td>A pattern for the filename for output OTU table files. The <code>AGP_100nt</code> (the data comes from the American Gut Project and sequences were trimmed to 100 nucleotides length). We can describe the <a href=\"#rare_params\">rarefaction depth</a> and <a href=\"#datasets\">body site</a> in the blanks.\n",
      "</td></tr>\n",
      "<tr><td><strong>map__fn</strong><br>(string)\n",
      "</td><td>A pattern for the filename for output mapping files. The <code>AGP_100nt</code> (the data comes from the American Gut Project and sequences were trimmed to 100 nucleotides length). We can describe the <a href=\"#rare_params\">rarefaction depth</a> and <a href=\"#datasets\">body site</a> in the blanks.\n",
      "</td></tr>\n",
      "<tr><td><strong>uud_fn</strong><br>(string)\n",
      "</td><td>A pattern for the file name used by unweighted UniFrac distance matrix files. The <code>AGP_100nt</code> (the data comes from the American Gut Project and sequences were trimmed to 100 nucleotides length). We can describe the <a href=\"#rare_params\">rarefaction depth</a> and <a href=\"#datasets\">body site</a> in the blanks.\n",
      "</td></tr>\n",
      "<tr><td><strong>wud_fn</strong><br>(string)\n",
      "</td><td>A pattern for the file name used by weighted UniFrac distance matrix files. The <code>AGP_100nt</code> (the data comes from the American Gut Project and sequences were trimmed to 100 nucleotides length). We can describe the <a href=\"#rare_params\">rarefaction depth</a> and <a href=\"#datasets\">body site</a> in the blanks.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "otu_fn = 'AGP_100nt%(rare_depth)s%(spacer)s%(site)s.biom'\n",
      "map_fn = 'AGP_100nt%(rare_depth)s%(spacer)s%(site)s.txt'\n",
      "uud_fn = 'unweighted_unifrac_AGP_100nt%(rare_depth)s%(spacer)s%(site)s.txt'\n",
      "wud_fn = 'weighted_unifrac_AGP_100nt%(rare_depth)s%(spacer)s%(site)s.txt'\n",
      "\n",
      "sin_fn = 'single_samples.txt'\n",
      "sub_fn = 'subset_samples.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir_blanks\"></a>\n",
      "### File pattern fill-in\n",
      "There are a set of blanks which are filled in for each file name. Some of these blanks will follow consistent patterns, which we can set before the files are used.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>map__extension</strong><br>(string)\n",
      "</td><td>The file extension for <a href=\"#ftype_map\">mapping files</a>. Mapping files are typically tab-delimited text files.\n",
      "</td></tr>\n",
      "<tr><td><strong>otu_extension</strong><br>(string)\n",
      "</td><td>The file extension for <a href=\"#ftype_otu\">OTU table files</a>. OTU tables are typically biom-formatted files.\n",
      "</td></tr>\n",
      "<tr><td>**rare_suffix** <br>(string)\n",
      "</td><td>This is added to file names to denote that rarefaction has occured. Typically, this should be <code><font color=\"FireBrick\">\u201ceven\u201d</font></code> with the rarefaction depth.\n",
      "</td></tr>\n",
      "<tr><td>**raw_suffix** <br>(string)\n",
      "</td><td>This is added to files in which rarefaction has not been performed. Usually, this will be an empty string. This is required to maintain appropriate string formatting.\n",
      "</td></tr>\n",
      "<tr><td><strong>site_pad</strong>; <strong>all_</strong><br>(string)\n",
      "</td><td>This is a spacer used to keep name formats clean and correct.\n",
      "</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map_extension = 'txt'\n",
      "otu_extension = 'biom'\n",
      "\n",
      "site_pad = '_'\n",
      "all_ = ''\n",
      "\n",
      "rare_suffix = '_even10k'\n",
      "raw_suffix = ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can set up the values to fill in the file blanks, now, using the body site names and the file paths we\u2019ve provided. We\u2019ll generate some of these using substitutions.\n",
      "\n",
      "<table id=\"params\">\n",
      "<tr><td><strong>last_rare</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for a rarefaction table or alpha diversity file. This is used to check if all rarefaction of alpha diversity files have been generated for an analysis.\n",
      "</td></tr>\n",
      "<tr><td><strong>all_raw_blanks</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for the unrarefied, all-sample files.\n",
      "</td></tr>\n",
      "<tr><td><strong>all_rare_blanks</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for the rarefied, all-sample files.\n",
      "</td></tr>\n",
      "<tr><td><strong>otu_raw_split_blanks</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for the unrarefied split file patterns to identify the split OTU table. The <code>nan</code> value for <code><font color=\"FireBrick\">split_group</font></code> is a place holder.\n",
      "</td></tr>\n",
      "<tr><td><strong>map_raw_split_blanks</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for the unrarefied split file patterns to identify the split metadata file. The <code>nan</code> value for <code><font color=\"FireBrick\">split_group</font></code> is a place holder.\n",
      "</td></tr>\n",
      "<tr><td><strong>otu_rare_split_blanks</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for the rarefied split file patterns to identify the split OTU table. The <code>nan</code> value for <code><font color=\"FireBrick\">split_group</font></code> is a place holder.\n",
      "</td></tr>\n",
      "<tr><td><strong>map_rare_split_blanks</strong><br />(dict)\n",
      "</td><td>Fills in the blanks for the rarefied split file patterns to identify the split metadata file. The <code>nan</code> value for <code><font color=\"FireBrick\">split_group</font></code> is a place holder.\n",
      "</td></tr>\n",
      "<tr><td><strong>raw_sample_blanks</strong><br />(list of dicts)\n",
      "</td><td>Fills in the blanks for the rarefied files at each body site. Here, we use list creation to fill in the blanks rather than using a placeholder.\n",
      "</td></tr>\n",
      "<tr><td><strong>rare_sample_blanks</strong><br />(list of dicts)\n",
      "</td><td>Fills in the blanks for the rarefied files at each body site. Here, we use list creation to fill in the blanks rather than using a placeholder.\n",
      "</td></tr>\n",
      "\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "last_rare = {'rare_depth': rarefaction_depth,\n",
      "             'rare_instance': num_rarefactions - 1}\n",
      "\n",
      "all_raw_blanks = {'rare_depth': raw_suffix,\n",
      "                  'spacer': all_,\n",
      "                  'site': all_}\n",
      "all_rare_blanks = {'rare_depth': rare_suffix,\n",
      "                   'spacer': all_,\n",
      "                   'site': all_}\n",
      "\n",
      "otu_raw_split_blanks = {'rare_suffix': raw_suffix,\n",
      "                        'split_field': split_field,\n",
      "                        'split_prefix': split_prefix,\n",
      "                        'split_group': np.nan,\n",
      "                        'extension': otu_extension}\n",
      "\n",
      "map_raw_split_blanks = {'rare_suffix': raw_suffix,\n",
      "                        'split_field': split_field,\n",
      "                        'split_prefix': split_prefix,\n",
      "                        'split_group': np.nan,\n",
      "                        'extension': map_extension}\n",
      "\n",
      "otu_rare_split_blanks = {'rare_suffix': rare_suffix,\n",
      "                         'split_field': split_field,\n",
      "                         'split_prefix': split_prefix,\n",
      "                         'split_group': np.nan,\n",
      "                         'extension': otu_extension}\n",
      "\n",
      "map_rare_split_blanks = {'rare_suffix': rare_suffix,\n",
      "                         'split_field': split_field,\n",
      "                         'split_prefix': split_prefix,\n",
      "                         'split_group': np.nan,\n",
      "                         'extension': map_extension}\n",
      "\n",
      "raw_sample_blanks = [{'site': site,\n",
      "                      'rare_depth': raw_suffix,\n",
      "                      'spacer': site_pad} for site in all_bodysites]\n",
      "\n",
      "rare_sample_blanks = [{'site': site,\n",
      "                       'rare_depth': rare_suffix,\n",
      "                       'spacer': site_pad} for site in all_bodysites]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"download\"></a>\n",
      "## Data Download\n",
      "\n",
      "We can now start our analysis by downloading the American Gut mapping file and OTU tables if they\u2019re not already located in the <code><strong>download_dir</strong></code>, they will be downloaded to this location. If the files exist, new versions will be downloaded only if <strong><code>overwrite</code></strong> is set to <code><font color=\"228B22\">True</font></code>. \n",
      "\n",
      "*Note that this step requires an internet connection.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets the biom file\n",
      "if not os.path.exists(download_otu_fp) or overwrite:\n",
      "    # Downloads the compressed biom file\n",
      "    !curl -OL https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.biom.gz\n",
      "     # Unzips the biom file\n",
      "    !gunzip ./AG_100nt.biom.gz\n",
      "    # Moves the biom file to its final location\n",
      "    shutil.move(os.path.join(os.path.abspath('.'), 'AG_100nt.biom'), download_otu_fp)\n",
      "\n",
      "# Gets the mapping file\n",
      "if not os.path.exists(download_map_fp) or overwrite:\n",
      "    # Downloads the mapping files\n",
      "    !curl -OL https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.txt\n",
      "    # Moves the file to the download file path\n",
      "    shutil.move(os.path.join('.', 'AG_100nt.txt'), download_map_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_clean\"></a>\n",
      "## Mapping File Clean up\n",
      "\n",
      "We may choose to massage the metadata before we do any work on the OTU table. This will correct errors and provide a uniform format for derived columns we may wish to use later or in downstream analyses. \n",
      "\n",
      "We\u2019ll start by loading the metadata. And then, we can address an error in the way the database retrieves answers for the <code>SEX</code>, <code>AGE_UNIT</code> and `DOMINANT_HAND` fields. We will also remove any sample dates which occurred before December 1, 2012, since no American Gut kits were available prior to this date.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loads the mapping file\n",
      "raw_map = pad_index(pd.read_csv(download_map_fp,\n",
      "                                sep=txt_delim, \n",
      "                                na_values=map_nas,\n",
      "                                index_col=False,\n",
      "                                parse_dates=date_cols,\n",
      "                                infer_datetime_format=True),\n",
      "                    index_col=map_index)\n",
      "\n",
      "# Loads the OTU table\n",
      "raw_otu = biom.load_table(download_otu_fp)\n",
      "\n",
      "# Filters the raw map to remove any samples that are not present in the biom table\n",
      "raw_map = raw_map.loc[raw_otu.ids()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cleans up the sex information based on a miscoding\n",
      "raw_map.loc[raw_map.SEX == '47', 'SEX'] = 'male'\n",
      "raw_map.loc[raw_map.SEX == '48', 'SEX'] = 'female'\n",
      "\n",
      "# Cleans up age information based on miscodeing\n",
      "raw_map.loc[raw_map.AGE_UNIT == '78', 'AGE_UNIT'] = 'years'\n",
      "\n",
      "# Cleans up handedness based on miscoding\n",
      "raw_map.loc[raw_map.DOMINANT_HAND == '151', 'DOMINANT_HAND'] = 'left'\n",
      "raw_map.loc[raw_map.DOMINANT_HAND == '152', 'DOMINANT_HAND'] = 'right'\n",
      "raw_map.loc[raw_map.DOMINANT_HAND == '153', 'DOMINANT_HAND'] = 'ambidextrous'\n",
      "\n",
      "# Removes the timestamp for any collection date prior to December 1, 2012\n",
      "crit_date = datetime.date(2012, 12, 1)\n",
      "raw_map.loc[raw_map.COLLECTION_DATE < crit_date, 'COLLECTION_DATE'] = pd.NaT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_age\"></a>\n",
      "### Age\n",
      "\n",
      "There are also a set of columns which are not included in the map, but may be useful for downstream analyses. These include age binned by decade (`AGE_CAT`). While there are Qiime analyses which can handle continuous metadata, binning can help reduce some of the noise.\n",
      "Here, we bin age by decade, with the exception of people under the age of 20. The gut develops in the first two years of life, and the guts of young children are significantly different than older children or adults [<a href=\"#20668239\">12</a>, <a href=\"#22699611\">13</a>]. We will also combine individuals over the age of 70 into their own category, due to the low sample counts of people over 80 as of round 14 (*n* < 20)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bins age by decade (with the exception of young children)\n",
      "def categorize_age(x):\n",
      "    if np.isnan(x):\n",
      "        return x\n",
      "    elif x < 3:\n",
      "        return \"baby\"\n",
      "    elif x < 13:\n",
      "        return \"child\"\n",
      "    elif x < 20:\n",
      "        return \"teen\"\n",
      "    elif x < 30:\n",
      "        return \"20s\"\n",
      "    elif x < 40:\n",
      "        return \"30s\"\n",
      "    elif x < 50:\n",
      "        return \"40s\"\n",
      "    elif x < 60:\n",
      "        return \"50s\"\n",
      "    elif x < 70:\n",
      "        return \"60s\"\n",
      "    else:\n",
      "        return \"70+\"\n",
      "raw_map['AGE_CAT'] = raw_map.AGE.apply(categorize_age)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_etoh\"></a>\n",
      "### Alcohol Consumption\n",
      "\n",
      "In addition to considering the frequency with which people use alcohol (Never, Rarely, Occasionally, Regularly, or Daily), it may be helpful to simply look for an effect associated with any alcohol consumption."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def categorize_etoh(x):\n",
      "    if x == 'Never':\n",
      "        return \"No\"\n",
      "    elif isinstance(x, str):\n",
      "        return \"Yes\"\n",
      "    elif np.isnan(x):\n",
      "        return x\n",
      "    \n",
      "raw_map['ALCOHOL_CONSUMPTION'] = raw_map.ALCOHOL_FREQUENCY.apply(categorize_etoh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_bmi\"></a>\n",
      "### Body Mass Index\n",
      "\n",
      "Body Mass Index (BMI) can be stratified into [categories](http://en.wikipedia.org/wiki/Body_mass_index#Categories) which give an approximate idea of body shape. It is worth noting that these stratifications do not hold well for growing children, where the BMI qualification is based on age and gender.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Categorizes the BMI into groups\n",
      "def categorize_bmi(x):\n",
      "    if np.isnan(x):\n",
      "        return x\n",
      "    elif x < 18.5:\n",
      "        return \"Underweight\"\n",
      "    elif x < 25:\n",
      "        return \"Normal\"\n",
      "    elif x < 30:\n",
      "        return \"Overweight\"\n",
      "    else:\n",
      "        return \"Obese\"\n",
      "raw_map['BMI_CAT'] = raw_map.BMI.apply(categorize_bmi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_date\"></a>\n",
      "### Collection Season\n",
      "\n",
      "American Gut samples have been collected since December of 2012. To look for patterns associated with the time of year samples were collected, we bin this date information into month, and season. \n",
      "\n",
      "We currently define our seasons according to the calendar in the Northern Hemisphere, because as of round 14, 99% of our samples were collected north of the equator. Additionally, rather than defining our seasons by the solar calendar, we have elected to use the first day of the month the solstice or equinox occurs in as the start of our season. So, while Winter technically begins on December 20th or 21st, according to the solar calendar, we consider December 1st as the first day of our Winter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Categorizes data by collection month and collection season\n",
      "month_map = {-1: [np.nan, np.nan],\n",
      "             np.nan: [np.nan, np.nan],\n",
      "             1: ['January', 'Winter'],\n",
      "             2: ['February', 'Winter'],\n",
      "             3: ['March', 'Spring'],\n",
      "             4: ['April', 'Spring'],\n",
      "             5: ['May', 'Spring'],\n",
      "             6: ['June', 'Summer'],\n",
      "             7: ['July', 'Summer'],\n",
      "             8: ['August', 'Summer'],\n",
      "             9: ['September', 'Fall'],\n",
      "             10: ['October', 'Fall'],\n",
      "             11: ['November', 'Fall'],\n",
      "             12: ['December', 'Winter']}\n",
      "\n",
      "# Maps the data as a month\n",
      "raw_map['COLLECTION_MONTH'] = \\\n",
      "    raw_map.COLLECTION_DATE.apply(lambda x:month_map[x.month][0])\n",
      "\n",
      "# Maps the data as a season\n",
      "raw_map['COLLECTION_SEASON'] = \\\n",
      "    raw_map.COLLECTION_DATE.apply(lambda x:month_map[x.month][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_loc\"></a>\n",
      "### Collection Location\n",
      "\n",
      "The American Gut Project includes some geographical information about where samples were collected. While the data may be leveraged as-is, it can also be helpful to clean up the data. Since participants in rounds 1-14 come predominantly from the US and Canada, we will only consider state/province information within these two countries in our cleaned up metadata. We will also reformat all states/provinces as two letter mailing codes (i.e. TX for Texas, BC for British Columbia). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Removes state information for any state not in the US\n",
      "# (This may change as additional countries are added.)\n",
      "countries = raw_map.groupby('COUNTRY').count().STATE.index.values\n",
      "for country in countries:\n",
      "    if country not in {'GAZ:United States of America', 'GAZ:Canada'}:\n",
      "        raw_map.loc[raw_map.COUNTRY == country, 'STATE'] = np.nan\n",
      "\n",
      "# Handles regional mapping, cleaning up states so that only American and\n",
      "# Canadian states are included \n",
      "def check_state(x):\n",
      "    if isinstance(x, str) and x in us_state_map:\n",
      "        return us_state_map[x.upper()]\n",
      "    elif  isinstance(x, str) and x in canadian_map_english:\n",
      "        return canadian_map_english[x.upper()]\n",
      "    else:\n",
      "        return np.nan\n",
      "raw_map['STATE'] = raw_map.STATE.apply(check_state)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We may also choose to use predefined regions to further bin our location data, and allow us to look for social or economic trends. To this end, we can apply regions defined by the [US Census Bureau](https://www.census.gov/geo/reference/gtc/gtc_census_divreg.html) and Economic Regions defined by the [US Bureau of Economic Analysis](http://www.bea.gov), which is part of the department of Commerce."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bins data by census region\n",
      "def census_f(x):\n",
      "    if  isinstance(x, str) and x in regions_by_state:\n",
      "        return regions_by_state[x]['Census_1']\n",
      "    else:\n",
      "        return np.nan\n",
      "raw_map['CENSUS_REGION'] = raw_map.STATE.apply(census_f)\n",
      "\n",
      "\n",
      "# Bins data by economic region\n",
      "def economic_f(x):\n",
      "    if isinstance(x, str) and  x in regions_by_state:\n",
      "        return regions_by_state[x]['Economic']\n",
      "    else:\n",
      "        return np.nan\n",
      "raw_map['ECONOMIC_REGION'] = raw_map.STATE.apply(economic_f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_sleep\"></a>\n",
      "### Sleep Duration\n",
      "\n",
      "As of round 14, there are less than 20 participants who report sleeping less than 5 hours a night. To all for a larger sample size, we will pool these with the individuals who report sleeping between 5 and 6 hours a night, to create a group who report lessing less than 6 hours a night."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_map.loc[raw_map.SLEEP_DURATION == 'Less than 5 hours', 'SLEEP_DURATION'] = 'Less than 6 hours'\n",
      "raw_map.loc[raw_map.SLEEP_DURATION == '5-6 hours', 'SLEEP_DURATION'] = 'Less than 6 hours'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"subset\"></a>\n",
      "## Identification of a Healthy Subset of Adults\n",
      "\n",
      "Certain health states are known to influence the microbiome in extreme ways. For some analyses we will do later, it may be useful to limit the noise associated with these conditions to allow us to look for new patterns. We have identified five metadata categories which we will use to limit our \u201chealthy\u201d subset.\n",
      "\n",
      "First, we limit based on age for several reasons. We chose to omit anyone under the age of twenty. The microbiome of very young children is not yet stable, and differs greatly from that of adults  [<a href=\"#20668239\">12</a>, <a href=\"#22699611\">13</a>]. Additionally, BMI limits are not easily assigned in people who are still growing. Without stratifying by gender, we assumed that growth will be complete in most people by the age of 20, and set our limit there. The limit at 70 was based on the number of individuals over the age of 70, and on differences in the microbiome seen in older individuals [<a href=\"#20571116\">14</a>, <a href=\"#22797518\">15</a>].\n",
      "\n",
      "We also used Body Mass Index as an exclusion criteria, considering only people in the \u201cnormal\u201d and \u201coverweight\u201d categories. (BMI 18.5 - 30). It has been suggested that obesity changes the gut microbiome, although the effect is not consistent across all studies [<a href=\"#25307765\">16</a>]. Additionally, we noticed that there were also alterations in our sample of underweight individuals.\n",
      "\n",
      "Recent antibiotic decreases alpha diversity and affects the microbiome [<a href=\"#20847294\">17</a>]. We chose to define \u201crecent\u201d as any time within the last year. We also excluded anyone who reported having Inflammatory Bowel Disease [<a href=\"#25307765\">16</a>], Type I Diabetes [<a href=\"#23274889\">18-21</a>], or Type II Diabetes [<a href=\"#20140211\">22</a>], since all three conditions are known to affect the microbiome.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates the subset if its not already in the mapping file\n",
      "if 'SUBSET' not in raw_map.columns:\n",
      "    subset_f = {'AGE': lambda x: 19 < x < 70 and not np.isnan(x),\n",
      "                'DIABETES': lambda x: x == 'I do not have diabetes',\n",
      "                'IBD': lambda x: x == 'I do not have IBD',\n",
      "                'ANTIBIOTIC_SELECT': lambda x: x == 'Not in the last year',\n",
      "                'BMI': lambda x: 18.5 <= x < 30 and not np.isnan(x)}\n",
      "\n",
      "    # Determines which samples meet the requirements of the categories\n",
      "    new_bin = {}\n",
      "    for cat, f in subset_f.iteritems():\n",
      "        new_bin[cat] = raw_map[cat].apply(f)\n",
      "\n",
      "    # Builds up the new binary dataframe\n",
      "    bin_frame = pd.DataFrame(new_bin)\n",
      "\n",
      "    # Adds a column to the current dataframe to look at the subset\n",
      "    bin_series = pd.DataFrame(new_bin).all(1)\n",
      "    bin_series.name = 'SUBSET'\n",
      "\n",
      "    raw_map = raw_map.join(bin_series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"rare\"></a>\n",
      "## Whole Table Rarefaction\n",
      "\n",
      "We will start by rarefying the whole body table using the rarefaction parameters we set earlier.  Rarefaction is a technique which filters out samples below a certain sequencing depth. Sequences are picked from a weighted average from the remaining samples to that all samples have an even depth. We can control for bias which might occur with a single, random subsampling of the data, we use multiple rounds of rarefaction to more accurately estimate the alpha diversity.\n",
      "\n",
      "Rarefaction is important to make intra sample diversity (alpha diversity) comparisons possible. Below is a panel from Figure 1 of Human Gut Microbiome and Risk of Colorectal Cancer[<a href=\"#24316595\">23</a>]. The figure compares Shannon Diversity between individuals with colorectal cancer (*n*=47, red circles) and healthy controls (*n*=94, empty triangles) over several rarefaction depths, or sequence counts per sample.\n",
      "\n",
      "![Cancer Rarefaction curve](https://raw.githubusercontent.com/JWDebelius/American-Gut/ipython/ipynb/images/ahn2013jncicolorectalf1.jpg)\n",
      "\n",
      "The figure also illustrates the importance of even sampling depth. If a control sample with 500 sequences per sample were compared with a cancer sample at a depth of 2500 sequences per sample, the cancer sample would appear more diverse. Comparisons at the same depth reveal the true pattern in the data: cancer samples are less diverse than controls.\n",
      "\n",
      "To perform multiple rarefactions, we will use the Qiime script, [multiple_rarefactions_even_depth.py](http://qiime.org/scripts/multiple_rarefactions_even_depth.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists(os.path.join(rare_dir, rare_pattern %last_rare)) or overwrite:\n",
      "    !multiple_rarefactions_even_depth.py -i $download_otu_fp -o $rare_dir -n $num_rarefactions -d $rarefaction_depth --lineages_included"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"alpha\"></a>\n",
      "## Whole Table Alpha Diversity\n",
      "\n",
      "We will use our rarefaction tables to calculate the alpha diversity associated with each rarefaction.  Alpha diversity is a measure of intra sample diversity. Imagine that we could put up an imaginary wall around a 100ft x 100ft x 10 ft box in Yellowstone National Park, trapping all the vertebrate animals in that area for a short period of time. Imagine that we then made a very careful list (or took photographs) of the area so that we could document all the life we found in the area. We could count all the different types of animals we found in that area. This would be one measure of alpha diversity. \n",
      "\n",
      "Say that rather than just considering each type of animal to be equally similar, we wanted to include an evolutionary relationship between the animals. So, if our area contained a mouse, a squirrel and a rabbit, we might say these animals are more similar (and therefore less diverse) than if we found a mouse, a squirrel, and a sagebrush lizard in the same area. So, even though we\u2019ve found three species in each case, the third species being a reptile would make it more diverse than the third species being a rodent. \n",
      "\n",
      "A diversity metric which accounts for shared evolutionary history between species is called a phylogenetic metric. This often uses a phylogenetic tree to provide information about that shared history. PD Whole Tree Diversity is a commonly used phylogenetic alpha diversity metric in microbiome research [<a href=\"#15831718\">8</a>]. A taxonomic metric assumes all species are equally different. Common taxonomic metrics for alpha diversity used  in microbiome research include Observed Species Diversity and Chao1 Diversity [<a href=\"#Chao\">9</a>; <a href=\"#shannon\">10</a>].\n",
      "\n",
      "Depending on what information we\u2019re looking for, we might want to include information about the number of each animal belonging to the species we see. We might also want to consider the number of each different species we find in the area, weighting our diversity. So, if in our little area of Yellowstone, 90% of the animals we see are mice, while 5% are rabbits and 5% are trout, we would consider this less diverse than if 40% of the animals were mice, 30% were rabbits and 30% were trout. A metric which takes into account the counts of each species is a quantitative metric, while a metric that looks only a the presence or absence of a species is a qualitative metric.\n",
      "\n",
      "While alpha diversity is calculated completely independently for each sample, the comparison of alpha diversity may provide clues about environmental changes. For example, pollution or an algal bloom may be associated with lower alpha diversity, and a change in the health of the ecosystem.\n",
      "We\u2019ll start our work with alpha diversity by calculating the diversity for our rarefied American Gut tables using the four metrics we selected in the alpha diversity parameters: the phylogenetic PD whole Tree Diversity, and the taxonomic metrics, Observed Species Diversity, Chao1 Diversity and Shannon Diversity. All the diversity metrics we are using here are qualitative metrics. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists(os.path.join(alpha_dir, alpha_pattern % last_rare)) or overwrite:\n",
      "    !alpha_diversity.py -i $rare_dir -o $alpha_dir -m $alpha_metrics -t $tree_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can load our alpha diversity results into our notebook, and collate them into a single table. We\u2019ll take the euclidian distance from each of these, and use it to identify the table where the alpha diversity is closest to the mean alpha diversity listed. This will be our best rarefaction instance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prealocates an output object for alpha diversity\n",
      "alpha_rounds = {'%s' % m: {} for m in alpha_metrics.split(',')}\n",
      "div_metric = alpha_metrics.split(',')[0]\n",
      "\n",
      "# Loops through the rarefaction instances\n",
      "for ri in range(num_rarefactions):\n",
      "    a_file_blanks = {'rare_depth': rarefaction_depth,\n",
      "                     'rare_instance': ri}\n",
      "    # Sets the alpha diveristy filepath\n",
      "    alpha_fp = os.path.join(alpha_dir, alpha_pattern) % a_file_blanks\n",
      "    # Loads the alpha diveristy table\n",
      "    alpha = pd.read_csv(alpha_fp,\n",
      "                        sep=txt_delim,\n",
      "                        index_col=False)\n",
      "    alpha.index = alpha['Unnamed: 0']\n",
      "    del alpha['Unnamed: 0']\n",
      "    \n",
      "    # Extracts the alpha diversity metrics\n",
      "    for col in alpha_rounds:\n",
      "        alpha_rounds[col]['%i' %ri] = alpha[col]\n",
      "        alpha_rounds[col]['%i' %ri].name = '%i' % ri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Complies the alpha diversity results into a single table\n",
      "alpha_df = pd.DataFrame({'%s_mean' % metric: pd.DataFrame(alpha_rounds[metric]).mean(1)\n",
      "                         for metric in alpha_metrics.split(',')})\n",
      "\n",
      "# Adds the alpha diversity results to the rarefied table\n",
      "rare_map = raw_map.copy()\n",
      "rare_map = rare_map.join(alpha_df)\n",
      "rare_check = np.isnan(rare_map['%s_mean' % div_metric]) == False\n",
      "rare_map = rare_map.loc[rare_check]\n",
      "\n",
      "# Draws the data assoicated with each of the alpha diveristy rounds\n",
      "all_rounds = pd.DataFrame(alpha_rounds[div_metric])\n",
      "\n",
      "# Lines up the data so the indices match (as a precaution)\n",
      "all_rounds = all_rounds.sort_index()\n",
      "alpha_df = alpha_df.sort_index()\n",
      "\n",
      "# Calculates the distance between each round and the mean\n",
      "mean_rounds = ([alpha_df['%s_mean' % div_metric].values] * \n",
      "               np.ones((num_rarefactions, 1))).transpose()\n",
      "diff = np.sqrt(np.square(all_rounds.values - np.square(mean_rounds))) / mean_rounds\n",
      "\n",
      "# Determines the minimum distance between the round and the mean\n",
      "round_labels = np.arange(0, 10)\n",
      "round_avg = diff.mean(0)\n",
      "\n",
      "best_rarefaction = round_labels[round_avg == min(round_avg)][0]\n",
      "best_blanks = {'rare_depth': rarefaction_depth,\n",
      "               'rare_instance': best_rarefaction}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We\u2019ll save the whole body tables in their own directory. We\u2019ll save the modified mapping files we\u2019ve massaged here. We\u2019ll also copy the raw OTU table and the rarefaction instance closest to the mean alpha diversity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Saves the unrarefied mapping file\n",
      "raw_map.to_csv(os.path.join(all_dir, map_fn) % all_raw_blanks,\n",
      "               sep=txt_delim,\n",
      "               na_rep=write_na,\n",
      "               index_label=map_index)\n",
      "\n",
      "# Saves the rarefied mapping file\n",
      "rare_map.to_csv(os.path.join(all_dir, map_fn) % all_raw_blanks,\n",
      "               sep=txt_delim,\n",
      "               na_rep=write_na,\n",
      "               index_label=map_index)\n",
      "\n",
      "# Copies the raw OTU table\n",
      "shutil.copy2(download_otu_fp, \n",
      "             os.path.join(all_dir, otu_fn) % all_raw_blanks)\n",
      "\n",
      "# Copies the rarefied OTU table\n",
      "shutil.copy2(os.path.join(rare_dir, rare_pattern) % best_blanks,\n",
      "             os.path.join(all_dir, otu_fn) % all_raw_blanks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"beta\"></a>\n",
      "## Whole Table Beta Diversity\n",
      "\n",
      "Beta Diversity allows us to make comparisons between samples and environments. Let\u2019s go back to our 100ft x 100ft x 10ft cube in Yellowstone where we catalogued all the vertebrates. Let\u2019s imagine that we\u2019ve set up the same type of cube in New York City\u2019s Central Park and cataloged all the vertebrates in that area as well. We want to be able to compare community structure. \n",
      "\n",
      "We could compare the two communities by seeing how many species are shared between the two, or, by make some measure that approximates the species. We might expect some overlap: depending on where we selected our regions, it would be unsurprising to encounter Chipmunks in both Central Park and Yellowstone National Park. However, there should also be some differences. Unless our Central Park location includes the zoo, it\u2019s unlikely we\u2019d find a Buffalo in New York City!\n",
      "\n",
      "If we use a taxonomic metric, based only on the species we find in the two locations, we might get very little overlap. While we might expect to find a squirrel in both Central Park and Yellowstone, the animals might be members of different genera! New York is home to the [Eastern Grey Squirrel](http://en.wikipedia.org/wiki/Eastern_gray_squirrel), *Sciurus carolinensis*, while we might find the [American Red Squirrel](http://en.wikipedia.org/wiki/American_red_squirrel), *Tamiasciurus hudsonicus*, in Yellowstone. [<a href=\"#yellowstone\">24</a>, <a href=\"#park\">25</a>]. In this case, a phylogenetic metric, which can account for some similarity between the two species of squirrels, may serve us much better.\n",
      "\n",
      "When we compare microbial communities for beta diversity, we frequently select a phylogenetic metric called UniFrac distance [<a href=\"#16332807\">5</a>]. This metric uses a phylogenetic tree, and determines what fraction of the tree is not shared between two communities. \n",
      "![UniFrac distance trees](http://unifrac.colorado.edu/static/images/fastunifrac/unifrac_significance/unifrac_test.jpg)\n",
      "\n",
      "If we consider only the presence and absence of each OTU in the samples, we have a qualitative metric, unweighted UniFrac distance. Unweighted UniFrac distance may take on values between 0 (everything the same) and 1 (everything different). Weighted UniFrac distance takes into account the abundance of the OTUs, and can take on values greater than 1.\n",
      "\n",
      "The UniFrac distance for each pairwise sample is arranged into a <a href=\"#ftype_dist\">Distance Matrix</a>. We can visualize the distance matrix by many techniques, like making PCoA plots in Emperor[<a href=\"#24280061\">2</a>], or UPGMA trees like the one shown in the figure below.\n",
      "\n",
      "![Unifrac to distance matrix](http://unifrac.colorado.edu/static/images/fastunifrac/cluster_samples/unifrac_clustering.jpg)\n",
      "\n",
      "Since UniFrac distance is calculated for each sample pair in the table, this is one of the most computationally expensive steps we will perform. However, once the UniFrac distance has been calculated for all of our samples, we can simply filter the table to focus on the samples we want. We can leverage the Qiime script, [beta_diveristy.py](http://qiime.org/scripts/beta_diversity.html) to perform our analysis.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up the filepaths for the all sample raried table\n",
      "all_otu_rare_fp = os.path.join(all_dir, otu_fn) % all_rare_blanks\n",
      "all_uud_rare_fp = os.path.join(all_dir, uud_fn) % all_rare_blanks\n",
      "all_wud_rare_fp = os.path.join(all_dir, wud_fn) % all_rare_blanks\n",
      "\n",
      "# Calculates the beta diversity\n",
      "if not (os.path.exists(all_uud_rare_fp) and \n",
      "        os.path.exists(all_wud_rare_fp)) or overwrite:\n",
      "    !beta_diversity.py -i $all_otu_rare_fp -m $beta_metrics -t $tree_fp -o $all_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Reutrn to the top</a>\n",
      "\n",
      "<a id=\"split\"></a>\n",
      "## Split the table by bodysite\n",
      "\n",
      "Now that we\u2019ve generated alpha and beta diversity results for all the body sites, we can start filtering the results. Body site has one of the largest impact on the microbiome in adult humans [<a href=\"#22699609\">7</a>]. As a result, many analyses will focus on a single body site, often fecal samples.\n",
      "\n",
      "We\u2019ll use the Qiime script, [split_otu_table.py](http://qiime.org/scripts/split_otu_table.html) to split our rarefied and unrarefied OTU tables by body site. We\u2019ll put the output files in intermediate directories, and then move and rename them in the appropriate locations.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets the raw location file names\n",
      "all_raw_otu_fp = os.path.join(all_dir, otu_fn) % all_rare_blanks\n",
      "all_raw_map_fp = os.path.join(all_dir, map_fn) % all_rare_blanks\n",
      "\n",
      "# Sets the rarefied location file names\n",
      "all_rare_otu_fp = os.path.join(all_dir, otu_fn) % all_rare_blanks\n",
      "all_rare_map_fp = os.path.join(all_dir, map_fn) % all_rare_blanks\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checks that the raw and rarified bodysite split tables exist\n",
      "raw_split_check = np.array([])\n",
      "rare_split_check = np.array([])\n",
      "\n",
      "for site in all_bodysites:\n",
      "    # Checks the unrarefied splits exists\n",
      "    otu_raw_split_blanks['split_group'] = site\n",
      "    map_raw_split_blanks['split_group'] = site\n",
      "    raw_otu_exist = os.path.exists(os.path.join(split_raw_dir, split_fn) \n",
      "                                   % otu_raw_split_blanks)\n",
      "    raw_map_exist = os.path.exists(os.path.join(split_raw_dir, split_fn) \n",
      "                                   % map_raw_split_blanks)\n",
      "    raw_split_check = np.hstack((raw_split_check, raw_otu_exist, raw_map_exist))\n",
      "    \n",
      "    # Checks the rarefied splits exist\n",
      "    otu_rare_split_blanks['split_group'] = site\n",
      "    map_rare_split_blanks['split_group'] = site\n",
      "    rare_otu_exist = os.path.exists(os.path.join(split_rare_dir, split_fn) \n",
      "                                   % otu_rare_split_blanks)\n",
      "    rare_map_exist = os.path.exists(os.path.join(split_rare_dir, split_fn) \n",
      "                                   % map_rare_split_blanks)\n",
      "    rare_split_check = np.hstack((rare_split_check, rare_otu_exist, rare_map_exist))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Splits the otu table and mapping file by bodysite\n",
      "if not raw_split_check.any():\n",
      "    !split_otu_table.py -i $all_raw_otu_fp -m $all_raw_map_fp -f BODY_HABITAT -o $split_raw_dir \n",
      "\n",
      "# Splits the otu table and mapping file by bodysite\n",
      "if not rare_split_check.any():\n",
      "    !split_otu_table.py -i $all_rare_otu_fp -m $all_rare_map_fp -f BODY_HABITAT -o $split_rare_dir "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We\u2019ll move and rename our split files to their final location."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copies the files to their correct final folder\n",
      "for idx, h_site in enumerate(habitat_sites):\n",
      "    otu_raw_split_blanks['split_group'] = h_site\n",
      "    map_raw_split_blanks['split_group'] = h_site\n",
      "    otu_rare_split_blanks['split_group'] = h_site\n",
      "    map_rare_split_blanks['split_group'] = h_site\n",
      "\n",
      "    # Copies the unrarefied mapping file\n",
      "    shutil.copy2(os.path.join(split_raw_dir, split_fn) \n",
      "                 % map_raw_split_blanks,\n",
      "                 os.path.join(asab_pattern, map_fn) \n",
      "                 % raw_sample_blanks[idx])\n",
      "\n",
      "    # Copies the unrarefied OTU table\n",
      "    shutil.copy2(os.path.join(split_raw_dir, split_fn) \n",
      "                 % otu_raw_split_blanks,\n",
      "                 os.path.join(asab_pattern, otu_fn) \n",
      "                 % raw_sample_blanks[idx])\n",
      "\n",
      "    # Copies the rarefied mapping file\n",
      "    shutil.copy2(os.path.join(split_rare_dir, split_fn) \n",
      "                 % map_rare_split_blanks,\n",
      "                 os.path.join(asab_pattern, map_fn) \n",
      "                 % rare_sample_blanks[idx])\n",
      "\n",
      "    # Copies the rarefied OTU table\n",
      "    shutil.copy2(os.path.join(split_rare_dir, split_fn) \n",
      "                 % otu_rare_split_blanks,\n",
      "                 os.path.join(asab_pattern, otu_fn)\n",
      "                 % rare_sample_blanks[idx])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get our distance matrices for each OTU table, we\u2019ll use the Qiime script, [filter_distance_matrix.py](http://qiime.org/scripts/filter_distance_matrix.html). We\u2019ll use the all sample mapping file, and select a \u201cvalid state\u201d, which is to say that we want the <code>BODY_HABITAT</code> field to be the correct bodysite (feces, oral cavity, or skin). We\u2019ll use this state to filter the all sample unweighted and weighted UniFrac tables, and save them in our new directory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, h_site in enumerate(habitat_sites):\n",
      "    \n",
      "    # Gets the rarefied mapping file for the site\n",
      "    map_in = os.path.join(asab_pattern, map_fn)  % rare_sample_blanks[idx]\n",
      "\n",
      "    # Sets up the unweighed filenames\n",
      "    uud_dm_in = os.path.join(all_dir, uud_fn) % all_rare_blanks\n",
      "    uud_dm_out = os.path.join(asab_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "\n",
      "    # Sets up the weighted filenames\n",
      "    wud_dm_in = os.path.join(all_dir, wud_fn) % all_rare_blanks\n",
      "    wud_dm_out = os.path.join(asab_pattern, wud_fn) % rare_sample_blanks[idx]\n",
      "    \n",
      "    # Filters the unweighted distance matrix\n",
      "    if not os.path.exists(uud_dm_out) or overwrite:\n",
      "        !filter_distance_matrix.py -i $uud_dm_in -o $uud_dm_out --sample_id_fp $map_in\n",
      "    \n",
      "    # Filters the weighted distance matrix\n",
      "    if not os.path.exists(wud_dm_out) or overwrite:\n",
      "        !filter_distance_matrix.py -i $wud_dm_in -o $wud_dm_out --sample_id_fp $map_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"single\"></a>\n",
      "## Select a Single Sample for Each Participant\n",
      "\n",
      "For some analyses we will choose to perform, it can be useful to work with a single sample for each participant at each body site. Many statistical tests assume sample independence. The microbiome among healthy adults is relatively stable across multiple samples within an individual; there is a higher correlation between your personal samples collected across several days than there is between your sample and another person\u2019s sample collected at the same time [<a href=\"#22699609\">7</a>].\n",
      "\n",
      "We\u2019re going to start defining our single sample data sets by writing a function which will allow us to randomly select a sample from each individual. This will take a pandas data map as an input. We\u2019ll group the data so we can look at each individual (given by the `HOST_SUBJECT_ID`), and then randomly select one sample id per individual.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def identify_single_samples(map_):\n",
      "    \"\"\"Selects a single sample for each participant\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    map_ : pandas DataFrame\n",
      "        A mapping file for our set of samples. A single body site should be\n",
      "        used with human samples.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    single_ids : ndarray\n",
      "        A list of ids which represent a single sample per individual\n",
      "\n",
      "    \"\"\"\n",
      "    # Identifies a single sample per individual\n",
      "    single_ids = np.hstack([np.random.choice(np.array(ids, dtype=str), 1)\n",
      "                            for indv, ids in\n",
      "                            map_.groupby('HOST_SUBJECT_ID').group.iteritems()])\n",
      "    return single_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We\u2019ll apply our filtering function at each bodysite. We\u2019ll start by setting up the file names for our all-sample data sets and file names for the new files we\u2019ll use for single samples. We\u2019ll also create a new text file which will contain a list of the single sample ids. \n",
      "\n",
      "Next, we\u2019ll use the function we just defined, **`identify_single_samples`**, to select a single sample for each participant at the body site we\u2019re examining. We\u2019ll use the rarefied body site mapping file. We can filter this easily in our notebook, and then we\u2019ll write the filtered mapping file to our new location.\n",
      "\n",
      "Finally, we\u2019ll leverage the qiime scripts, biom subset-table and [filter_distance_matrix.py](http://qiime.org/scripts/filter_distance_matrix.html) to filter our OTU table and distance matrices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a_site in all_bodysites:\n",
      "    # Skips any site not suggested in our list\n",
      "    if a_site not in one_samp_sites:\n",
      "        continue\n",
      "    # Sets up names for the all sample files\n",
      "    site_map_fp = os.path.join(asab_pattern, map_fn) % rare_sample_blanks[idx]\n",
      "    site_otu_fp = os.path.join(asab_pattern, otu_fn) % rare_sample_blanks[idx]\n",
      "    site_uud_fp = os.path.join(asab_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "    site_wud_fp = os.path.join(asab_pattern, wud_fn) % rare_sample_blanks[idx]\n",
      "\n",
      "    # Sets up names for the single sample files\n",
      "    sin_site_map_fp = os.path.join(assb_pattern, map_fn) % rare_sample_blanks[idx]\n",
      "    sin_site_otu_fp = os.path.join(assb_pattern, otu_fn) % rare_sample_blanks[idx]\n",
      "    sin_site_uud_fp = os.path.join(assb_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "    sin_site_wud_fp = os.path.join(assb_pattern, wud_fn) % rare_sample_blanks[idx]\n",
      "    sin_site_ids_fp = os.path.join(assb_pattern, sin_fn) % {'site': a_site}\n",
      "\n",
      "    if overwrite or not (os.path.exists(sin_site_ids_fp) and \n",
      "                         os.path.exists(sin_site_map_fp)):\n",
      "        # Reads in the rarefied table specific to the body site\n",
      "        site_map = pad_index(pd.read_csv(site_map_fp,\n",
      "                                         sep=txt_delim, \n",
      "                                         na_values=map_nas,\n",
      "                                         index_col=False,\n",
      "                                         parse_dates=date_cols,\n",
      "                                         infer_datetime_format=True),\n",
      "                             index_col=map_index)\n",
      "        # Filters the OTU table down to single samples\n",
      "        site_otu = biom.load_table(site_otu_fp)\n",
      "\n",
      "        # Filters the table so only the samples that are present in both tables are considered\n",
      "        site_map = site_map.loc[site_otu.ids(axis='sample')]\n",
      "\n",
      "        # Selects single sample ids\n",
      "        single_site_ids = identify_single_samples(site_map)\n",
      "\n",
      "        # Saves the single ids file\n",
      "        sin_ids_file = file(sin_site_ids_fp, 'w')\n",
      "        sin_ids_file.write('\\n'.join(list(single_site_ids)))\n",
      "        sin_ids_file.close()\n",
      "\n",
      "        # Gets the single sample per participant body site map\n",
      "        single_site_map = site_map.loc[single_site_ids]\n",
      "        single_site_otu = site_otu.filter(single_site_ids, axis='sample')\n",
      "\n",
      "        # Saves the single sample map\n",
      "        single_site_map.to_csv(sin_site_map_fp,\n",
      "                               sep=txt_delim,\n",
      "                               na_rep=write_na,\n",
      "                               index_label=map_index)\n",
      "\n",
      "    # Filters the OTU table down to single samples\n",
      "    if not os.path.exists(sin_site_otu_fp) or overwrite:\n",
      "        !biom subset-table -i $site_otu_fp -o $sin_site_otu_fp -a sample -s $sin_site_ids_fp\n",
      "        \n",
      "    # Filters the distance matrices\n",
      "    if not os.path.exists(sin_site_uud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $site_uud_fp -o $sin_site_uud_fp --sample_id_fp $sin_site_ids_fp\n",
      "    if not os.path.exists(sin_site_wud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $site_wud_fp -o $sin_site_wud_fp --sample_id_fp $sin_site_ids_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"filt_subset\"></a>\n",
      "## Filter the healthy sample subset\n",
      "\n",
      "Finally, we may wish to have a healthy subset of individuals for certain analyses. The criteria we\u2019ve used to define the healthy subset are described <a href=\"#subset\">above</a>. We\u2019ll use essentially the same pipeline we leveraged for filtering the single samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, a_site in enumerate(all_bodysites):\n",
      "    # Skips any site where the healthy subset criteria should not be applied\n",
      "    if a_site not in sub_part_sites:\n",
      "        continue\n",
      "    \n",
      "    # Sets up the filepaths for import and starting files\n",
      "    all_map_fp = os.path.join(asab_pattern, map_fn) % rare_sample_blanks[idx]\n",
      "    all_otu_fp = os.path.join(asab_pattern, otu_fn) % rare_sample_blanks[idx]\n",
      "    all_uud_fp = os.path.join(asab_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "    all_wud_fp = os.path.join(asab_pattern, wud_fn) % rare_sample_blanks[idx]   \n",
      "    \n",
      "    # Sets up the file paths for file returns\n",
      "    sub_map_fp = os.path.join(ssab_pattern, map_fn) % rare_sample_blanks[idx]\n",
      "    sub_otu_fp = os.path.join(ssab_pattern, otu_fn) % rare_sample_blanks[idx]\n",
      "    sub_uud_fp = os.path.join(ssab_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "    sub_wud_fp = os.path.join(ssab_pattern, wud_fn) % rare_sample_blanks[idx]\n",
      "    sub_ids_fp = os.path.join(ssab_pattern, sub_fn) % {'site': a_site}\n",
      "            \n",
      "    # We'll start by generating a list of the subset of samples\n",
      "    if overwrite or not (os.path.exists(sub_ids_fp) and \n",
      "                          os.path.exists(sub_map_fp)):\n",
      "        # Loads the all sample mapping file\n",
      "        all_map = pad_index(pd.read_csv(all_map_fp,\n",
      "                                        sep=txt_delim, \n",
      "                                        na_values=map_nas,\n",
      "                                        index_col=False,\n",
      "                                        parse_dates=date_cols,\n",
      "                                        infer_datetime_format=True),\n",
      "                            index_col=map_index)\n",
      "        # Filters the table for the healthy subset of ids\n",
      "        sub_map = all_map.loc[all_map.SUBSET]\n",
      "        \n",
      "        # Gets the list of ids associted with the healthy subset\n",
      "        subset_ids = sub_map.index.values\n",
      "                \n",
      "        # Saves the healthy subset list of ids\n",
      "        sub_ids_file = file(sub_ids_fp, 'w')\n",
      "        sub_ids_file.write('\\n'.join(list(subset_ids)))\n",
      "        sub_ids_file.close()\n",
      "        \n",
      "        sub_map.to_csv(sub_map_fp,\n",
      "                       sep=txt_delim,\n",
      "                       na_rep=write_na,\n",
      "                       index_label=map_index)\n",
      "        \n",
      "    # Filters the OTU table\n",
      "    if not os.path.exists(sub_otu_fp) or overwrite:\n",
      "        !biom subset-table -i $all_otu_fp -o $sub_otu_fp -a sample -s $sub_ids_fp\n",
      "        \n",
      "    # Filters the distance matrices\n",
      "    if not os.path.exists(sub_uud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_uud_fp -o $sub_uud_fp --sample_id_fp $sub_ids_fp\n",
      "    if not os.path.exists(sub_wud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_wud_fp -o $sub_wud_fp --sample_id_fp $sub_ids_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, a_site in enumerate(all_bodysites):\n",
      "    # Skips any site where the healthy subset criteria should not be applied\n",
      "    if a_site not in sub_part_sites or a_site not in one_samp_sites:\n",
      "        continue\n",
      "    \n",
      "    # Sets up the filepaths for import and starting files\n",
      "    sample_spaces = (a_site, rare_suffix, site_pad, a_site)\n",
      "    all_map_fp = os.path.join(assb_pattern, map_fn) % rare_sample_blanks[idx]\n",
      "    all_otu_fp = os.path.join(assb_pattern, otu_fn) % rare_sample_blanks[idx]\n",
      "    all_uud_fp = os.path.join(assb_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "    all_wud_fp = os.path.join(assb_pattern, wud_fn) % rare_sample_blanks[idx]\n",
      "    \n",
      "    # Sets up the file paths for file returns\n",
      "    sub_map_fp = os.path.join(sssb_pattern, map_fn) % rare_sample_blanks[idx]\n",
      "    sub_otu_fp = os.path.join(sssb_pattern, otu_fn) % rare_sample_blanks[idx]\n",
      "    sub_uud_fp = os.path.join(sssb_pattern, uud_fn) % rare_sample_blanks[idx]\n",
      "    sub_wud_fp = os.path.join(sssb_pattern, wud_fn) % rare_sample_blanks[idx]\n",
      "    sub_ids_fp = os.path.join(sssb_pattern, sub_fn) % {'site': a_site}\n",
      "            \n",
      "    # We'll start by generating a list of the subset of samples\n",
      "    if overwrite or not (os.path.exists(sub_ids_fp) and \n",
      "                          os.path.exists(sub_map_fp)):\n",
      "        # Loads the all sample mapping file\n",
      "        all_map = pad_index(pd.read_csv(all_map_fp,\n",
      "                                        sep=txt_delim, \n",
      "                                        na_values=map_nas,\n",
      "                                        index_col=False,\n",
      "                                        parse_dates=date_cols,\n",
      "                                        infer_datetime_format=True),\n",
      "                            index_col=map_index)\n",
      "        # Filters the table for the healthy subset of ids\n",
      "        sub_map = all_map.loc[all_map.SUBSET]\n",
      "        \n",
      "        # Gets the list of ids associted with the healthy subset\n",
      "        subset_ids = sub_map.index.values\n",
      "                \n",
      "        # Saves the healthy subset list of ids\n",
      "        sub_ids_file = file(sub_ids_fp, 'w')\n",
      "        sub_ids_file.write('\\n'.join(list(subset_ids)))\n",
      "        sub_ids_file.close()\n",
      "        \n",
      "        sub_map.to_csv(sub_map_fp,\n",
      "                       sep=txt_delim,\n",
      "                       na_rep=write_na,\n",
      "                       index_label=map_index)\n",
      "        \n",
      "    # Filters the OTU table\n",
      "    if not os.path.exists(sub_otu_fp) or overwrite:\n",
      "        !biom subset-table -i $all_otu_fp -o $sub_otu_fp -a sample -s $sub_ids_fp\n",
      "        \n",
      "    # Filters the distance matrices\n",
      "    if not os.path.exists(sub_uud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_uud_fp -o $sub_uud_fp --sample_id_fp $sub_ids_fp\n",
      "    if not os.path.exists(sub_wud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_wud_fp -o $sub_wud_fp --sample_id_fp $sub_ids_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"conclusions\"></a>\n",
      "You have now generated cleaned up, rarefied OTU tables, mapping files with alpha diversity and UniFrac distance matrices for our American Gut Data, as well as creating focused datasets. We can choose to create further-filtered tables, or we can take the outputs of this notebook and use it for downstream analysis.\n",
      "\n",
      "\n",
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"references\"></a>\n",
      "## References\n",
      "<ol><li><a id=\"20383131\"></a>Caporaso, J.G.; Kuczynski, J.; Strombaugh, J.; Bittinger, K.; Bushman, F.D.; Costello, E.K.; Fierer, N.; Pe\u00f1a, A.G., Goodrich, J.K.; Gordon, J.I.; Huttley, G.A.; Kelley, S.T.; Knights, D.; Koenig, J.E.; Ley, R.E.; Lozupone, C.A.; McDonald, D.; Muegge, B.D.; Pirrung, M.; Reeder, J.; Sevinsky, J.R.; Turnbaugh, P.J.; Walters, W.A.; Widmann, J.; Yatsunenko, T.; Zaneveld, J. and Knight, R. (2010) \u201c<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/20383131\">Qiime allows analysis of high-throughput community sequence data.</a>\u201d *Nature Methods*. **7**: 335 - 336. <br>   \n",
      "</li><li><a id=\"24280061\"></a>V&aacute;zquez-Baeza, Y.; Pirrung, M.; Gonzalez, A.; and Knight, R. (2013). \u201c<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/24280061\">EMPeror: a tool for visualizing high-throughput microbial community data.</a>\u201d *Gigascience*. **2**: 16.<br>   \n",
      "</li><li><a id=\"23975157\"></a>Langille, M.G.; Zaneveld, J.; Caporaso, J.G.; McDonald, D.; Knights, D.; Reyes, J.A.; Clemente, J.C.; Burkepile, D.E.; Vega Thurber, R.L.; Knight, R.; Beiko, R.G.; and Huttenhower, C. (2013). \u201c<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/23975157\">Predictive functional profiling of microbial communities using 16S rRNA marker gene sequences.</a>\u201d *Nat Biotechnol*. **31**: 814-821.<br>   \n",
      "</li><li><a id=\"23587224\"></a>McDonald, D.; Clemente, J.C.; Kuczynski, J.; Rideout, J.R.; Stombaugh, J.; Wendel, D.; Wilke, A.; Huse, S.; Hufnagle, J.; Meyer, F.; Knight, R.; and Caporaso, J.G. (2012). \u201c<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/23587224\">The Biological Observation Matrix (BIOM) format or: how I learned to stop worrying and love the ome-ome.</a>\u201d  Gigascience. 1:7.<br>   \n",
      "</li><li><a id=\"16332807\"></a>Lozupone, C.; and Knight, R. (2005). \u201c<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16332807\">UniFrac: a new phylogenetic method for comparing microbial communities.</a>\u201d *Appl Enviro Microbiol.* **71**: 8228-8235.<br>   \n",
      "</li><li><a id=\"20827291\"></a>Lozupone, C.; LLadser, M.E.; Knights, D.; Stombaugh, J.; and Knight, R. (2011). \u201c<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/20827291\">UniFrac: an effective distance metric for microbial community composition.</a>\u201d *ISME J* **5**: 169-172.<br>   \n",
      "</li><li><a id=\"22699609\"></a>The Human Microbiome Consortium. (2012) \u201c[Structure, Function and diversity of the healthy human microbiome.](http://www.ncbi.nlm.nih.gov/pubmed/22699609)\u201d *Nature*. **486**: 207-214.<br>   \n",
      "</li><li><a id=\"15831718\"></a>Eckburg, P.B.; Bik, E.M.; Bernstein C.N.; Purdom, E.; Dethlefson, L.; Sargent, M.; Gill, S.R.; Nelson, K.E.; Relman, D.A. (2005) \u201c[Diversity of the human intestinal microbial flora.](http://www.ncbi.nlm.nih.gov/pubmed/15831718)\u201d *Science*. **308**: 1635-1638.<br>   \n",
      "</li><li><a id=\"chao\"></a>Chao, A. (1984) \u201c[Nonparametric estimation of the number of classes in a population](http://viceroy.eeb.uconn.edu/estimateS/EstimateSPages/EstSUsersGuide/References/Chao1984.pdf).\u201d *Scandinavian J  Stats*. **11**: 265-270.<br>   \n",
      "</li><li><a id=\"shannon\"></a>Seaby, R.M.H. and Henderson, P.A. (2006). \u201cSpecies Diversity and Richness 4.\u201d http://www.pisces-conservation.com/sdrhelp/index.html. <br>   \n",
      "</li><li><a id=\"22134646\"></a>McDonald, D.; Price, N.M.; Goodrich, J.; Nawrocki, E.P.; DeSantis, T.Z.; Probst, A.; Andersen, G.L.; Knight, R. and Hugenholtz, P. (2012). \u201c[An improved Greengenes taxonomy with explicit ranks for ecological and evolutionary analyses of bacteria and archaea.](http://www.ncbi.nlm.nih.gov/pubmed/22134646)\u201d *ISME J*. **6**:610 - 618.<br>   \n",
      "</li><li><a id=\"20668239\"></a>Koenig, J.E.; Spor, A.; Scalfone, N.; Fricker, A.D.; Stombaugh, J.; Knight, R.; Angenent, L.T.; and Ley, R.E. (2011). \u201c[Succession of microbial consortia in the developing infant gut microbiome](http://www.ncbi.nlm.nih.gov/pubmed/20668239).\u201d *PNAS*. **108 Suppl 1**: 4578 - 4585.<br>   \n",
      "</li><li><a id=\"22699611\"></a>Yatsunenko, T.; Rey, F.E.; Manary, M.J.; Trehan, I.; Dominguez-Bello, M.G.; Contreras, M.; Magris, M.; Hidalgo, G.; Baldassano, R.N.; Anokhin, A.P.; Heath, A.C.; Warner, B.; Rdder, J.; Kuczynski, J.; Caporaso, J.G.; Lozupone, C.A.; Lauber, C.; Clemente, J.C.; Knights, D.; Knight, R. and Gordon, J.I. (2012) \u201c[Human Gut microbiome viewed across age and geography](http://www.ncbi.nlm.nih.gov/pubmed/22699611).\u201d *Nature*. **486**: 222-227.<br>   \n",
      "</li><li><a id=\"20571116\"></a>Claesson, M.J.; Cusacks, S.; O\u2019Sullivan, O.; Greene-Diniz, R.; de Weerd, H.; Flannery, E.; Marchesi, J.R.; Falush, D.; Dinan, T.; Fitzgerald, G.; Stanton, C.; van Sinderen, D.; O\u2019Connor, M.; Harnedy, N.; O\u2019Connor, K.; Henry, C.; O\u2019Mahony, D.; Fitzgerald, A.P.; Shananhan, F.; Twomey, C.; Hill, C.; Ross, R.P.; and O\u2019Toole, P.W. (2011). \u201c[Composition, variability and temporal stability of the intestinal microbiota of the elderly](http://www.ncbi.nlm.nih.gov/pubmed/20571116).\u201d *PNAS*. **108 Suppl 1**: 4586 - 4591.<br>   \n",
      "</li><li><a id=\"22797518\"></a>Claesson, M.J.; Jeffery, I.B.; Conde, S.; Power, S.E.; O\u2019Connor, E.M.; Cusack, S.; Harris, H.M.; Coakley, M.; Lakshminarayanan, B.; O\u2019Sullivan, O.; Fitzgerald, G.F; Deane, J.; O\u2019Connor, M.; Harnedy, N.; O\u2019Connor, K.; O\u2019Mahony, D.; van Sinderen, D.; Wallace, M.; Brennan, L.; Stanton, C.; Marchesi, J.R.; Fitzgerald, A.P.; Shanahan, F.; Hill, C.; Ross, R.P.; and O\u2019Toole, P.W. (2012). \u201c[Gut microbiota composition correlates with diet and health in the elderly](http://www.ncbi.nlm.nih.gov/pubmed/22797518).\u201d *Nature*. **488**: 178-184.<br>   \n",
      "</li><li><a id=\"25307765\"></a>Walters, W.A.; Zu, Z.; and Knight, R. (2014) \u201c[Meta-analysis of human gut microbes associated with obesity and IBD](http://www.ncbi.nlm.nih.gov/pubmed/25307765).\u201d FEBS Letters. 588: 4223-4233.<br>   \n",
      "</li><li><a id=\"20847294\"></a> Dethlefsen, L. and Relman, D.A. (2011) \u201c[Incomplete recovery and individualized responses of the human distal gut microbiota to repeated antibiotic perturbation](http://www.ncbi.nlm.nih.gov/pubmed/20847294).\u201d PNAS. 108 Suppl 1: 4554-4561.<br>   \n",
      "</li><li><a id=\"23274889\"></a> de Goffau, M.C.; Luopaj\u00e4rvi, K.; Knip, M.; Ilonen, J.; Ruohtula, T.; H\u00e4rk\u00f6nen, T.; Orivuori, L.; Hakala, S.; Welling, G.W.; Harmensen, H.J.; and Vaarala, O. (2013). \u201c[Fecal Microbiota composition differs between children with B-cell autoimmunity and those without](http://www.ncbi.nlm.nih.gov/pubmed/23274889).\u201d Diabetes. 62: 1238-1244.<br>   \n",
      "</li><li><a id=\"20613793\"></a> Giongo, A.; Gano, K.A.; Crabb, D.B.; Mukherjee, N.; Novelo, L.L.; Casella, G.; Drew, J.C.; Ilonen, J.; Knip, M.; Hy\u00f6ty, H; Veijola, R.; Simell, T.; Simell, O.; Neu, J.; Wasserfall, C.H.; Schatz, D.; Atkinson, M.A.; and Triplett, E.W. (2011). \u201c[Toward defining the autoimmune microbiome for type 1 diabetes](http://www.ncbi.nlm.nih.gov/pubmed/20613793).\u201d ISME J. 5: 82-91.<br>   \n",
      "</li><li><a id=\"24448554\"></a> Mej\u00eda-Le\u00f3n, M.E.; Petrosino, J.F.; Ajami, N.J.; Dom\u00ednguez-Bello, M.G.; and de la Barca, A.M. (2014). \u201c[Fecal microbiota imbalance in Mexican children with type 1 diabetes](http://www.ncbi.nlm.nih.gov/pubmed/24448554).\u201d Science Reports. 4: 3814.<br>   \n",
      "</li><li><a id=\"23433344\"></a> Murrim M.; Leiva, I.; Gomez-Zumaquero, J.M.; Tinahones, F.J.; Cardona, F.; Soriguer, F.; and Queipo-Ortu\u00f1o, M.I. (2013). \u201c[Gut microbiota in children with type 1 diabetes differs from that in healthy children: a case-control study](http://www.ncbi.nlm.nih.gov/pubmed/23433344).\u201d BMC Med. 11:46.<br>   \n",
      "</li><li><a id=\"20140211\"></a>Larsen, N.; Vogensen, F.K.; van den Berg, F.W.; Nielsen, D.S.; Andreasen, A.S.; Pedersen, B.K.; Al-Soud, W.A.; S\u00f8rensen, S.J.; Hansen, H.L. and Jakobsen, M. (2010). \u201c[Gut Microbiota in human adults with type 2 diabetes differs from non diabetic adults](http://www.ncbi.nlm.nih.gov/pubmed/20140211).\u201d PLoS One. 5: e9085.<br>   \n",
      "</li><li><a id=\"24316595\"></a>Ahn, J.; Sinha, R.; Pei, Z.; Cominanni, C.; Wu, J.; Shi, J.; Goedert, J.J.; Hayes, R.B.; and Yang, L. (2013). \"[Human gut microbiome and risk for colorectal cancer](http://www.ncbi.nlm.nih.gov/pubmed/24316595).\" *J Natl Cancer Inst.* **105**: 1907-1911.<br>   \n",
      "</li><li><a id=\"yellowstone\"></a>National Park Service. (2015). \u201c[Mammal Checklist](http://www.nps.gov/yell/naturescience/mammalscheck.htm).\u201d *Yellowstone National Park*. <br>   \n",
      "</li><li><a id=\"park\"></a> Milieris, V. (2011) \u201c[Biodiversity in Central Park](http://macaulay.cuny.edu/eportfolios/themanhattanproject/does-central-park-work/biodiversity-in-central-park-virginia-milieris/)\u201d. *Exploring Central Park*. CUNY.\n",
      "\n",
      "\n",
      "</li></ol>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}